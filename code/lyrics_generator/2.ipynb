{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../data/EdmondsDance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = np.array([\n",
    "            \"Joy\",\n",
    "            \"Trust\",\n",
    "            \"Fear\",\n",
    "            \"Surprise\",\n",
    "            \"Sadness\",\n",
    "            \"Disgust\",\n",
    "            \"Anger\",\n",
    "            \"Anticipation\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artists</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anticipation</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Apollo</td>\n",
       "      <td>Hardwell, Amba Shepherd</td>\n",
       "      <td>Just one day in the life&lt;br&gt;So I can understan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lullaby</td>\n",
       "      <td>R3HAB, Mike Williams</td>\n",
       "      <td>Hypnotized, this love out of me&lt;br&gt;Without you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Melody (Tip Of My Tongue)</td>\n",
       "      <td>Mike Williams</td>\n",
       "      <td>I stand a little too close&lt;br&gt;You stare a litt...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Take Me Home</td>\n",
       "      <td>Cash Cash, Bebe Rexha</td>\n",
       "      <td>I'm falling to pieces&lt;br&gt;But I need this&lt;br&gt;Ye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>City of Dreams</td>\n",
       "      <td>Dirty South, Alesso</td>\n",
       "      <td>Everything seems like a city of dreams,&lt;br&gt;I n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Song                  Artists  \\\n",
       "0           0                     Apollo  Hardwell, Amba Shepherd   \n",
       "1           1                    Lullaby     R3HAB, Mike Williams   \n",
       "2           2  Melody (Tip Of My Tongue)            Mike Williams   \n",
       "3           3               Take Me Home    Cash Cash, Bebe Rexha   \n",
       "4           4             City of Dreams     Dirty South, Alesso    \n",
       "\n",
       "                                              Lyrics  Joy  Trust  Fear  \\\n",
       "0  Just one day in the life<br>So I can understan...    1      1     0   \n",
       "1  Hypnotized, this love out of me<br>Without you...    0      0     1   \n",
       "2  I stand a little too close<br>You stare a litt...    1      1     0   \n",
       "3  I'm falling to pieces<br>But I need this<br>Ye...    0      0     0   \n",
       "4  Everything seems like a city of dreams,<br>I n...    0      0     0   \n",
       "\n",
       "   Surprise  Sadness  Disgust  Anger  Anticipation  Unnamed: 11  \n",
       "0         1        0        0      0             0          NaN  \n",
       "1         0        1        0      0             0          NaN  \n",
       "2         0        0        0      0             1          NaN  \n",
       "3         1        1        1      0             0          NaN  \n",
       "4         1        1        0      0             0          NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = raw_df[raw_df[\"Sadness\"] == 1][\"Lyrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      Hypnotized, this love out of me<br>Without you...\n",
       "3      I'm falling to pieces<br>But I need this<br>Ye...\n",
       "4      Everything seems like a city of dreams,<br>I n...\n",
       "5      You end up alone after all that you've done<br...\n",
       "6      Nobody here knocking at my door<br>The sound o...\n",
       "                             ...                        \n",
       "511    Over my head, over my head, over my head<br>Ov...\n",
       "514    Cause I've been faking<br>Faking it for too lo...\n",
       "521    There's not enough room in here<br>For room fo...\n",
       "522    I see you everywhere<br>I never moved on<br>Wi...\n",
       "523    These stars are, really fireflies that lost th...\n",
       "Name: Lyrics, Length: 185, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_corpus():\n",
    "    corpus = {}\n",
    "    for emotion_label in emotion_labels:\n",
    "        lyrics_series = raw_df[raw_df[emotion_label] == 1][\"Lyrics\"]\n",
    "        corpus[emotion_label] = list(lyrics_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_song_series = raw_df[raw_df[\"labels\"].str.contains(\"Sadness\")][\"lyrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_song_series = [[\"\"\"I walk a lonely road\n",
    "The only one that I have ever known\n",
    "Don't know where it goes\n",
    "But it's home to me, and I walk alone\n",
    "I walk this empty street\n",
    "On the Boulevard of Broken Dreams\n",
    "Where the city sleeps\n",
    "And I'm the only one, and I walk alone\n",
    "I walk alone, I walk alone\n",
    "I walk alone, I walk a-\n",
    "My shadow's the only one that walks beside me\n",
    "My shallow heart's the only thing that's beating\n",
    "Sometimes, I wish someone out there will find me\n",
    "'Til then, I walk alone\n",
    "Ah-ah, ah-ah, ah-ah, ah-ah\n",
    "Ah-ah, ah-ah, ah-ah\n",
    "I'm walking down the line\n",
    "That divides me somewhere in my mind\n",
    "On the borderline\n",
    "Of the edge, and where I walk alone\n",
    "Read between the lines\n",
    "What's fucked up, and everything's alright\n",
    "Check my vital signs\n",
    "To know I'm still alive, and I walk alone\n",
    "I walk alone, I walk alone\n",
    "I walk alone, I walk a-\n",
    "My shadow's the only one that walks beside me\n",
    "My shallow heart's the only thing that's beating\n",
    "Sometimes, I wish someone out there will find me\n",
    "'Til then, I walk alone\n",
    "Ah-ah, ah-ah, ah-ah, ah-ah\n",
    "Ah-ah, ah-ah, I walk alone, I walk a-\n",
    "I walk this empty street\n",
    "On the Boulevard of Broken Dreams\n",
    "Where the city sleeps\n",
    "And I'm the only one, and I walk a-\n",
    "My shadow's the only one that walks beside me\n",
    "My shallow heart's the only thing that's beating\n",
    "Sometimes, I wish someone out there will find me\n",
    "'Til then, I walk alone\"\"\"], [\"\"\"\n",
    "I've got a really bad disease\n",
    "It's got me begging on my hands and knees\n",
    "So take me to emergency\n",
    "'Cause something seems to be missing\n",
    "Somebody take the pain away\n",
    "It's like an ulcer bleeding in my brain\n",
    "So send me to the pharmacy\n",
    "So I can lose my memory\n",
    "I'm elated, medicated\n",
    "Lord knows I've tried to find a way\n",
    "To run away\n",
    "I think they found another cure\n",
    "For broken hearts and feeling insecure\n",
    "You'd be surprised what I endure\n",
    "What makes you feel so self-assured?\n",
    "I need to find a place to hide\n",
    "You never know what could be waiting outside\n",
    "The accidents that you could find\n",
    "It's like some kind of suicide\n",
    "So what ails you is what impales you?\n",
    "I feel like I've been crucified\n",
    "To be satisfied\n",
    "I'm a victim of my symptom\n",
    "I am my own worst enemy\n",
    "You're a victim of your symptom\n",
    "You are your own worst enemy\n",
    "Know your enemy\n",
    "I'm elated, medicated\n",
    "I am my own worst enemy\n",
    "So what ails you is what impales you?\n",
    "You are your own worst enemy\n",
    "You're a victim of the system\n",
    "You are your own worst enemy\n",
    "You're a victim of the system\n",
    "You are your own worst enemy\n",
    "\"\"\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_song_corpus = []\n",
    "for song in sad_song_series[:30]:\n",
    "    sad_song_corpus.append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sad_song_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk  # just for tokenization\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "def tokenize(lyrics: list[str]) -> list[list[str]]:\n",
    "    result = []\n",
    "    for lyric in tqdm(lyrics):\n",
    "        # lowercase the text, remove stop words, punctuation and keep only the words\n",
    "        tokens = nltk.tokenize.word_tokenize(lyric.lower())\n",
    "        stop_words = list(string.punctuation)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        alpha_tokens = [\n",
    "            lemmatizer.lemmatize(token)\n",
    "            for token in tokens\n",
    "        ]\n",
    "        result.append(alpha_tokens)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 349.07it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenize(sad_song_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:07<06:16,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0 LOSS: 299593.471495945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:15<06:13,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 LOSS: 269491.02277823794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:23<06:05,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2 LOSS: 248249.59396214937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:31<05:56,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3 LOSS: 239605.4665509529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:38<05:47,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4 LOSS: 234336.441573547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:46<05:37,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5 LOSS: 230432.79940085826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:54<05:33,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 6 LOSS: 227492.61383429117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [01:01<05:25,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 7 LOSS: 225246.7599968805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [01:09<05:18,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 8 LOSS: 223439.686465251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:17<05:08,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 9 LOSS: 221932.95347756558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:25<05:03,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10 LOSS: 220648.414751821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [01:33<04:55,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11 LOSS: 219539.64690401318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [01:40<04:46,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12 LOSS: 218582.9520970906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [01:48<04:38,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13 LOSS: 217761.52630828513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:56<04:32,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14 LOSS: 217053.2688801467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [02:03<04:23,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15 LOSS: 216435.01269048676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [02:11<04:15,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16 LOSS: 215887.78627634738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [02:19<04:08,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17 LOSS: 215396.93034678642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [02:27<04:00,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18 LOSS: 214951.2431143629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [02:34<03:50,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19 LOSS: 214542.26886833904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [02:42<03:43,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20 LOSS: 214163.6899112441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [02:50<03:36,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 21 LOSS: 213810.7922298619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [02:58<03:29,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 22 LOSS: 213480.02348164888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [03:06<03:22,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 23 LOSS: 213168.64963218433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [03:13<03:14,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 24 LOSS: 212874.50381355186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [03:21<03:06,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 25 LOSS: 212595.8169647212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [03:29<02:57,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 26 LOSS: 212331.1123582849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [03:36<02:50,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 27 LOSS: 212079.13917531312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [03:44<02:42,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 28 LOSS: 211838.82521459175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [03:52<02:33,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 29 LOSS: 211609.24008531234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [04:00<02:27,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 30 LOSS: 211389.56662069497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [04:09<02:28,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 31 LOSS: 211179.0792980546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [04:18<02:26,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 32 LOSS: 210977.1282319045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [04:28<02:23,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 33 LOSS: 210783.12737366243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [04:39<02:23,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 34 LOSS: 210596.5457767941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [04:50<02:19,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 35 LOSS: 210416.9009998177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [05:01<02:12, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 36 LOSS: 210243.75392635877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [05:12<02:04, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 37 LOSS: 210076.70449908884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [05:22<01:55, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 38 LOSS: 209915.38806806758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [05:33<01:44, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 39 LOSS: 209759.47220698275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [05:42<01:30, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 40 LOSS: 209608.65393612688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [05:51<01:17,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 41 LOSS: 209462.65731391523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [05:59<01:05,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 42 LOSS: 209321.2313367964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [06:08<00:54,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 43 LOSS: 209184.14804516864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [06:16<00:44,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 44 LOSS: 209051.20069988832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [06:24<00:34,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 45 LOSS: 208922.20189431214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [06:33<00:25,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 46 LOSS: 208796.98150943543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [06:40<00:16,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 47 LOSS: 208675.3844934413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [06:48<00:08,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 48 LOSS: 208557.26852929682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:56<00:00,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 49 LOSS: 208442.50172048277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "class word2vec():\n",
    "    def __init__ (self):\n",
    "        self.n = settings['n']\n",
    "        self.eta = settings['learning_rate']\n",
    "        self.epochs = settings['epochs']\n",
    "        self.window = settings['window_size']\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def generate_training_data(self, settings, corpus):\n",
    "\n",
    "        word_counts = defaultdict(int)\n",
    "        for row in corpus:\n",
    "            for word in row:\n",
    "                word_counts[word] += 1\n",
    "\n",
    "        self.v_count = len(word_counts.keys())\n",
    "\n",
    "        self.words_list = sorted(list(word_counts.keys()),reverse=False)\n",
    "        self.word_index = dict((word, i) for i, word in enumerate(self.words_list))\n",
    "        self.index_word = dict((i, word) for i, word in enumerate(self.words_list))\n",
    "\n",
    "        training_data = []\n",
    "        for sentence in corpus:\n",
    "            sent_len = len(sentence)\n",
    "\n",
    "            \n",
    "            for i, word in enumerate(sentence):\n",
    "                \n",
    "                \n",
    "                w_target = self.word2onehot(sentence[i])\n",
    "\n",
    "                \n",
    "                w_context = []\n",
    "                for j in range(i-self.window, i+self.window+1):\n",
    "                    if j!=i and j<=sent_len-1 and j>=0:\n",
    "                        w_context.append(self.word2onehot(sentence[j]))\n",
    "                training_data.append([w_target, w_context])\n",
    "        \n",
    "        return training_data\n",
    "\n",
    "\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    def word2onehot(self, word):\n",
    "        word_vec = [0 for i in range(0, self.v_count)]\n",
    "        word_index = self.word_index[word]\n",
    "        word_vec[word_index] = 1\n",
    "        return word_vec\n",
    "\n",
    "\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        h = np.dot(self.w1.T, x)\n",
    "        u = np.dot(self.w2.T, h)\n",
    "        y_c = self.softmax(u)\n",
    "        return y_c, h, u\n",
    "                \n",
    "\n",
    "    \n",
    "    def backprop(self, e, h, x):\n",
    "        dl_dw2 = np.outer(h, e)  \n",
    "        dl_dw1 = np.outer(x, np.dot(self.w2, e.T))\n",
    "\n",
    "        \n",
    "        self.w1 = self.w1 - (self.eta * dl_dw1)\n",
    "        self.w2 = self.w2 - (self.eta * dl_dw2)\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self, training_data):\n",
    "        \n",
    "        limit1 = np.sqrt(2 / float(self.n + self.v_count))\n",
    "        self.w1 = np.random.normal(\n",
    "                0.0, limit1, size=(self.v_count, self.n)\n",
    "            )     # embedding matrix\n",
    "        self.w2 = np.random.normal(\n",
    "                0.0, limit1, size=(self.n, self.v_count)\n",
    "            ) \n",
    "        \n",
    "        \n",
    "        for i in tqdm(range(0, self.epochs)):\n",
    "\n",
    "            self.loss = 0\n",
    "\n",
    "            \n",
    "            for w_t, w_c in training_data:\n",
    "\n",
    "                \n",
    "                y_pred, h, u = self.forward_pass(w_t)\n",
    "                \n",
    "                \n",
    "                EI = np.sum([np.subtract(y_pred, word) for word in w_c], axis=0)\n",
    "\n",
    "                \n",
    "                self.backprop(EI, h, w_t)\n",
    "\n",
    "                \n",
    "                self.loss += -np.sum([u[word.index(1)] for word in w_c]) + len(w_c) * np.log(np.sum(np.exp(u)))\n",
    "                \n",
    "            print('EPOCH:',i, 'LOSS:', self.loss)\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    def word_vec(self, word):\n",
    "        w_index = self.word_index[word]\n",
    "        v_w = self.w1[w_index]\n",
    "        return v_w\n",
    "\n",
    "\n",
    "    \n",
    "    def vec_sim(self, vec, top_n):\n",
    "\n",
    "        \n",
    "        word_sim = {}\n",
    "        for i in range(self.v_count):\n",
    "            v_w2 = self.w1[i]\n",
    "            theta_num = np.dot(vec, v_w2)\n",
    "            theta_den = np.linalg.norm(vec) * np.linalg.norm(v_w2)\n",
    "            theta = theta_num / theta_den\n",
    "\n",
    "            word = self.index_word[i]\n",
    "            word_sim[word] = theta\n",
    "\n",
    "        words_sorted = sorted(word_sim.items(), key=lambda item:item[1], reverse=True)\n",
    "\n",
    "        return words_sorted\n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "    def word_sim(self, word, top_n):\n",
    "        \n",
    "        w1_index = self.word_index[word]\n",
    "        v_w1 = self.w1[w1_index]\n",
    "\n",
    "        \n",
    "        word_sim = {}\n",
    "        for i in range(self.v_count):\n",
    "            v_w2 = self.w1[i]\n",
    "            theta_num = np.dot(v_w1, v_w2)\n",
    "            theta_den = np.linalg.norm(v_w1) * np.linalg.norm(v_w2)\n",
    "            theta = theta_num / theta_den\n",
    "\n",
    "            word = self.index_word[i]\n",
    "            word_sim[word] = theta\n",
    "\n",
    "        words_sorted = sorted(word_sim.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        words = []\n",
    "        for word in words_sorted[:top_n]:\n",
    "            words.append(word[0])\n",
    "\n",
    "        return words\n",
    "\n",
    "\n",
    "settings = {}\n",
    "settings['n'] = 5                   # dimension of word embeddings\n",
    "settings['window_size'] = 2         # context window +/- center word\n",
    "settings['min_count'] = 0           # minimum word count\n",
    "settings['epochs'] = 50       # number of training epochs\n",
    "settings['neg_samp'] = 10           # number of negative words to use during training\n",
    "settings['learning_rate'] = 0.01    # learning rate\n",
    "np.random.seed(0)                   # set the seed for reproducibility\n",
    "\n",
    "corpus = tokens\n",
    "\n",
    "w2v = word2vec()\n",
    "\n",
    "# generate training data\n",
    "training_data = w2v.generate_training_data(settings, corpus)\n",
    "\n",
    "# train word2vec model\n",
    "w2v.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 76.68it/s]\n"
     ]
    }
   ],
   "source": [
    "n_words = 100\n",
    "previous_word = initial_token = \"i\"\n",
    "predicted_lyrics = initial_token\n",
    "previous_five_words = [initial_token]\n",
    "\n",
    "for _ in tqdm(range(n_words)):\n",
    "    count = 0\n",
    "    tentaitve_next_words = w2v.word_sim(previous_word, 10)\n",
    "    \n",
    "    tentaitve_next_word = np.random.choice(tentaitve_next_words + [\",\",\".\"])\n",
    "    if tentaitve_next_word in [\",\",\".\"]:\n",
    "        previous_five_words.append(tentaitve_next_word)\n",
    "        predicted_lyrics += f\" {tentaitve_next_word}\"\n",
    "\n",
    "    else:\n",
    "        while count < 10 and (tentaitve_next_word in previous_five_words):\n",
    "            tentaitve_next_word = tentaitve_next_words[count]\n",
    "            count += 1\n",
    "\n",
    "        predicted_lyrics += f\" {tentaitve_next_word}\"\n",
    "        if len(previous_five_words) == 5:\n",
    "            previous_five_words.pop(0)\n",
    "        \n",
    "        previous_word = tentaitve_next_word\n",
    "        previous_five_words.append(previous_word)\n",
    "    # if tentaitve_next_word  not in [\",\", \".\"]:\n",
    "    #     previous_five_words.append(previous_word)\n",
    "    #     previous_word = tentaitve_next_word\n",
    "    # else:\n",
    "    #     previous_word = previous_five_words[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i x2 whiskey , man because gonzales young , count sat angel next by lonely easily sitting foster getting wild bullet naked wall , passing wondering stuck meal buoy business morning mornin room bring thought golden breaking keats hungry . , violent , . dying flame resuscitation burn heat deep collection clip . banana too bargain strait eternity ak men grave split peeping as weird infatuated doomed crime fantasy married singing awake closest dark tarnish father acting beaten living navigational gate bird prisoner , myself fell sick whence enough way limit , sussed visit pump tear , fill recall offend who-ever'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1331, 5)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.64879883,  1.75212071, -0.73838378,  0.54868277, -0.42380714])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.w1[582]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"w1.npy\", w2v.w1)\n",
    "np.save(\"w2.npy\", w2v.w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"word_index.npy\", w2v.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.load(\"word_index.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_index.json', 'w') as json_file:\n",
    "    json.dump(w2v.word_index, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1331"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.v_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_word.json', 'w') as json_file:\n",
    "    json.dump(w2v.index_word, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess-engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
